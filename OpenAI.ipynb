{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c3d2586-fdb8-41d7-81b0-2d0a47d9d785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import dotenv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62c741df-f591-4684-8ecf-0d069f4e72c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'role' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 49\u001b[0m\n\u001b[0;32m     46\u001b[0m results_esp \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tweet \u001b[38;5;129;01min\u001b[39;00m output_esp:\n\u001b[1;32m---> 49\u001b[0m     resp \u001b[38;5;241m=\u001b[39m openAI_classificator(\u001b[43mrole\u001b[49m, tweet)\n\u001b[0;32m     50\u001b[0m     index \u001b[38;5;241m=\u001b[39m labels_esp\u001b[38;5;241m.\u001b[39mindex(resp)\n\u001b[0;32m     51\u001b[0m     histogram_esp[index] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'role' is not defined"
     ]
    }
   ],
   "source": [
    "#Haciendo uso de openAI para clasificaci칩n\n",
    "outputs_esp_eng = pd.read_csv('outputs_esp_eng.csv')\n",
    "output_esp = outputs_esp_eng['output_esp'].values.tolist()\n",
    "output_eng = outputs_esp_eng['output_eng'].values.tolist()\n",
    "\n",
    "config = dotenv.dotenv_values(\".env\")\n",
    "openai.api_key = config['OPENAI_API_KEY']\n",
    "\n",
    "def openAI_classificator(role, text):\n",
    "    response = openai.ChatCompletion.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "        {\n",
    "          \"role\": \"system\",\n",
    "          \"content\": role\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": text\n",
    "        }\n",
    "      ],\n",
    "      temperature=0,\n",
    "      max_tokens=100,\n",
    "      top_p=1,\n",
    "      frequency_penalty=0,\n",
    "      presence_penalty=0\n",
    "    )\n",
    "\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "role_esp = \"Se te otorgar치 un tweet, y tu tarea ser치 determinar si ese texto est치 'fuertemente en contra', \\\n",
    "'en contra', 'neutral', 'a favor', o 'fuertemente a favor' de la candidatura de Donald Trump. Solo retorna la \\\n",
    "etiqueta. Si no tienes suficiente contexto, retorna 'Ninguna', por favor.\"\n",
    "\n",
    "role_eng = \"You will be given a tweet, and your task will be to determine if that text is 'strongly against',\\\n",
    "'against', 'neutral', 'in favor', or 'strongly in favor' of Donald Trump's candidacy. Just return the \\\n",
    "label. If you don't have enough context, return 'None', please.\"\n",
    "\n",
    "labels_esp = ['fuertemente en contra', 'en contra', 'neutral', 'a favor', 'fuertemente a favor']\n",
    "labels_eng = ['strongly against', 'against', 'neutral', 'in favor', 'strongly in favor']\n",
    "\n",
    "histogram_eng = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "histogram_esp = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "\n",
    "results_eng = []\n",
    "results_esp = []\n",
    "\n",
    "for tweet in output_esp:\n",
    "    resp = openAI_classificator(role_esp, tweet)\n",
    "    index = labels_esp.index(resp)\n",
    "    histogram_esp[index] += 1.0\n",
    "    results_esp.append(tweet + ' ' + resp)\n",
    "\n",
    "for tweet in output_eng:\n",
    "    resp = openAI_classificator(role_eng, tweet)\n",
    "    index = labels_eng.index(resp)\n",
    "    histogram_eng[index] += 1.0\n",
    "    results_eng.append(tweet + ' ' + resp)\n",
    "\n",
    "histograms = pd.DataFrame(data = {'histogram_esp' : histogram_esp, 'histogram_eng': histogram_eng })\n",
    "histograms.to_csv(path_or_buf='histograms_openAI.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d56e795-9f2a-4ac4-ab03-bcf767708327",
   "metadata": {},
   "outputs": [],
   "source": [
    "histograms_transformers = pd.read_csv('histograms_transformers.csv')\n",
    "histograms_openAI = pd.read_csv('histograms_openAI.csv')\n",
    "\n",
    "histogram_esp_tr = histograms_transformers['histogram_esp'].values.tolist()\n",
    "histogram_eng_tr = histograms_transformers['histogram_eng'].values.tolist()\n",
    "\n",
    "histogram_esp_ai = histograms_transformers['histogram_esp'].values.tolist()\n",
    "histogram_eng_ai = histograms_transformers['histogram_eng'].values.tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
